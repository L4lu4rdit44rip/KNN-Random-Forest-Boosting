# -*- coding: utf-8 -*-
"""Lalu Ardita Arip_proyek 1_terapan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X0IVPHQ8CmFpu7C5gj-EMN1O9tdy2k_d

#Proyek Pertama
#Nama : Lalu Ardita Arip
#SIB ID : M302X0788
#Email : ardita.arip18@gmail.com
#Email :M302X0788@dicoding.org
#alamat : Lombok Timur, NTB
#kode kelas : M-08

link dataset :https://www.kaggle.com/datasets/adhurimquku/ford-car-price-prediction

melakukan loading data agar data lebih mudah diproses
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns
from sklearn import linear_model
from sklearn.ensemble import AdaBoostRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.preprocessing import  OneHotEncoder

data = pd.read_csv('ford.csv')
data

"""dari data diatas diproleh ada 17.966 baris dalam dataset, dan terdapat 9 kolom yang terdiri dari kolom: model,	year,	price,	transmission,	mileage,	fuelType,	tax,	mpg,	engineSize"""

# melihat informasi dari dataset
data.info()

"""dari informasi diatas diperoleh informasi bahwa: 3 kolom objek yang merupkan kategorikal fitur. 2 kolom float64 ynag merupakan fitur numerik yang dilakukan dengan pengukuran. dan 4 kolom int64 yang didalamnya terdapat target yang akan kita ukur """

# mengecek deskripsi statistik data
data.describe()

"""dari fungsi diatas kita dapat menerima informasi statistik pada masing-masing kolom """

mileage = (data.mileage == 0).sum()
tax = (data.tax == 0).sum()
mpg = (data.mpg == 0).sum()
engineSize = (data.engineSize == 0).sum()
 
print("Nilai 0 di kolom mileage ada: ", mileage)
print("Nilai 0 di kolom tax ada: ", tax)
print("Nilai 0 di kolom mpg ada: ", mpg)
print("Nilai 0 di kolom engineSize ada: ", engineSize)

"""sebelum memperoses datanya lebih lanjut kita terlebih dahulu harus melakukan pemeriksaan terhadap missing value, kaliini kita akan memerikas missing value pada kolom mileage, tax, mpg, dan engineSize"""

data.loc[(data['tax']==0)]

"""melakukan pengecekan data pada kolom tax, apakah data bernilai 0 terdapat pula pada dimensilainnya"""

# Drop baris dengan nilai 'mileage','tax','mpg','engineSize' = 0
data = data.loc[(data[['mileage','tax','mpg','engineSize']]!=0).all(axis=1)]
 
# Cek ukuran data untuk memastikan baris sudah di-drop
data.shape

"""menghilangkan/menghapus baris bernilai 0 sehingga baris/data berupabah menjadi 15.769"""

data.describe()

"""memastikan tidak ada missing value pada dataset tersebut."""

sns.boxplot(x=data['year'])

sns.boxplot(x=data['mileage'])

sns.boxplot(x=data['tax'])

sns.boxplot(x=data['mpg'])

sns.boxplot(x=data['engineSize'])

"""melakuakan visualisasi pada dataset dengan menggunkan boxplot untuk mendeteksi outliers pada fitur numerik"""

Q1 = data.quantile(0.25)
Q3 = data.quantile(0.75)
IQR=Q3-Q1
data=data[~((data<(Q1-1.5*IQR))|(data>(Q3+1.5*IQR))).any(axis=1)]
 
# Cek ukuran dataset setelah kita drop outliers
data.shape

"""membuat batasan pada dataset dengan membuat batas atas dan batas bawah. setelah membuat batas atas dan bawah sekarang kita memiliki dataset yang berseih  dengan memiliki 8.401 sampel."""

numerical_features = ['year',	'price',	'mileage',	'tax',	'mpg',	'engineSize']
categorical_features = ['model', 'transmission', 'fuelType']

"""melakukan analisis dengan menggunakan teknik Univariate EDA, langakah pertama yang kita lakukan dengan car amembagi dua dataset menjadi fitur numrikal dan kategorikal.

categorical features
"""

feature = categorical_features[0]
count = data[feature].value_counts()
percent = 100*data[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""terdapat 18 kategori pada fitur model dengan persentasi fiesat dengan model terbanyak dan musatang merupakan model dengan persentasi paling sedikit"""

feature = categorical_features[1]
count = data[feature].value_counts()
percent = 100*data[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""pada transmission terdapat transmission manual, automatic dan semi-auto, dengan manual memiliki persentasi paling tinggi."""

feature = categorical_features[2]
count = data[feature].value_counts()
percent = 100*data[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""pada tipe bahan bakar terdiri dari petrol, diesel dan hybrid. dan dengan penggunaan bahan bakara petrol yang paling banyak.

numrical features
"""

data.hist(bins=50, figsize=(20,15))
plt.show()

"""yang menjadi fokus utama kita pada lebel harga. sehingga dari histogram tersebut kita mendapat beberapa informasi seperti rentang harga mobil, dan jumlah unit dengan harga demikian"""

cat_features = data.select_dtypes(include='object').columns.to_list()
 
for col in cat_features:
  sns.catplot(x=col, y="price", kind="bar", dodge=False, height = 4, aspect = 3,  data=data, palette="Set3")
  plt.title("Rata-rata 'price' Relatif terhadap - {}".format(col))

"""dari catplot diatas kita dapat melihat pengaruh fitur kategori terhadap harga mobil tersebut. misalkan mustang merupakan model dengan harga rata-rata termahal, dan tranmisi automatic merupakan rata-rata tranmisis termalah serta type bahan abakar hybrid/campuran merupakan bahan bakar dengan harga rata-rata termahal."""

# Mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(data, diag_kind = 'kde')

"""dengan pairplot diatas kita dapat melihat relasi pasangan dalam dataset kita."""

plt.figure(figsize=(10, 8))
correlation_matrix = data.corr().round(2)
 
# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""dari corelasi diatas dapat kita lihat bahawa koralasi antara harga dan mpg merupakan korelasi dengan tingkat paling rendah."""

data.drop(['mpg'], inplace=True, axis=1)
data.head()

"""karena korelasi dengan mpg merupakan yang terendah fitur mpg dapat di hapus."""

data = pd.concat([data, pd.get_dummies(data['model'], prefix='model')],axis=1)
data = pd.concat([data, pd.get_dummies(data['transmission'], prefix='transmission')],axis=1)
data = pd.concat([data, pd.get_dummies(data['fuelType'], prefix='fuelType')],axis=1)
data.drop(['model', 'transmission', 'fuelType'], axis=1, inplace=True)
data.head()

"""melakukan peroses encoding pada fitur kategori agar mendapat fitur baru. peroses encoding kali ini menggunakan fitur get_dummies"""

sns.pairplot(data[['mileage','tax','engineSize']], plot_kws={"s": 3});

"""setelah melakukan pengecekan menggunakan fungsi pairplot ketiga fitur tersebut memiliki korelasi yang rendah karena mengandung informasi yang berbeda."""

pca = PCA(n_components=3, random_state=123)
pca.fit(data[['mileage','tax','engineSize']])
princ_comp = pca.transform(data[['mileage','tax','engineSize']])

"""mengapilkasikan celas PCA dari library scikit learn."""

pca.explained_variance_ratio_.round(3)

"""dari class PCA kita bisi mengetahui proforsi informasi dari ketiga informasi. dan berdasarkan informasi tersebut kita akan mereduksi komponen JPU dan mempertahankan komponen pertama saja."""

pca = PCA(n_components=1, random_state=123)
pca.fit(data[['mileage','tax','engineSize']])
data['JPU'] = pca.transform(data.loc[:, ('mileage','tax','engineSize')]).flatten()
data.drop(['mileage','tax','engineSize'], axis=1, inplace=True)

"""disini kita membuat fitur baru yaitu JPU yang merupakan gabungan dari fitur 'mileage','tax','engineSize'"""

X = data.drop(["price"],axis =1)
y = data["price"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""membagi dataset menjadi data latih dan data uji agar lebih mempermudah dengan perbandingan 80:20 dengan fungsi train_test_split dari sklearn."""

numerical_features = ['year', 'JPU']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

"""menerapkan StandardScaler pada data. """

X_train[numerical_features].describe().round(4)

"""standarisasi mengubah nilai rata-rata (mean) menjadi 0 dan nilai standar deviasi menjadi 1"""

# Siapkan dataframe untuk analisis model
models = pd.DataFrame(index=['train_mse', 'test_mse'], 
                      columns=['KNN', 'RandomForest', 'Boosting'])

knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(X_train, y_train) 
models.loc['train_mse','knn'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)

"""dengan menggunakan KNN dengan menggunakan K=10 tetangga dan metric Euclidean untuk mengukur jarak antara titik."""

# buat model prediksi
RF = RandomForestRegressor(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
RF.fit(X_train, y_train)
models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

"""lalu kita menggunakan random forest ynag dimana algoritma ini disiusun dari banyak decision tree ynag dimana pembagian data dan fiturnya dipilih secara acak."""

boosting = AdaBoostRegressor(learning_rate=0.05, random_state=55)                             
boosting.fit(X_train, y_train)
models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

"""menggunakan boosting ynag dimana tkehnik ini melatih model seacra berurutan atau dalam proses yag iteratif

selajutnya tahap evalusai
"""

# Lakukan scaling terhadap fitur numerik pada X_test sehingga memiliki rata-rata=0 dan varians=1
X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

"""terlebih dahulu kita melakukan scaling agar sekala antara data uji dan data latih sama dan dapat dilakukan evaluasi"""

# Buat variabel mse yang isinya adalah dataframe nilai mse data train dan test pada masing-masing algoritma
mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting'])
# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'KNN': knn, 'RF': RF, 'Boosting': boosting}
# Hitung Mean Squared Error masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3 
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3
# Panggil mse
mse

"""melakukan evaluasi pada ketiga model dengan matrik MSE"""

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""agar lebih mempermudah gunkana visualisasi menggunakan barchart"""

prediksi = X_test.iloc[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in model_dict.items():
    pred_dict[name] = model.predict(prediksi).round(1)
 
pd.DataFrame(pred_dict)

"""dari hasil diats terlihat bahwa perdiksi dengan menggunakan KNN lebih mendekati """